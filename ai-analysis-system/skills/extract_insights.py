"""
AIä¿¡æ¯åˆ†æç³»ç»Ÿ - æ´å¯Ÿæå–æŠ€èƒ½

ä»processingæ–‡ä»¶å¤¹æå–ç²¾åå†…å®¹ç”Ÿæˆç¬”è®°ä¿å­˜åˆ°outputã€‚
"""

from datetime import datetime
from pathlib import Path
from typing import List, Optional

import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from core import (
    file_manager,
    content_parser,
    news_analyzer,
    NamingConfig,
    OUTPUT_DIR,
)


def extract_insights(
    source_files: Optional[List[Path]] = None,
    importance_filter: str = "high",
    output_subfolder: str = "notes"
) -> dict:
    """
    ä»processingæå–ç²¾åå†…å®¹ç”Ÿæˆç¬”è®°
    
    Args:
        source_files: æºæ–‡ä»¶åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºprocessingä¸­æ‰€æœ‰æ–‡ä»¶
        importance_filter: é‡è¦æ€§è¿‡æ»¤ï¼ˆhigh/medium/low/allï¼‰
        output_subfolder: è¾“å‡ºå­æ–‡ä»¶å¤¹
        
    Returns:
        æå–ç»“æœå­—å…¸
    """
    # è·å–processingä¸­çš„æ–‡ä»¶
    if source_files is None:
        all_files = file_manager.list_all_files("processing")
        source_files = [
            Path(f["path"]) 
            for f in all_files.get("processing", [])
        ]
    
    if not source_files:
        return {
            "insights_extracted": 0,
            "message": "processingæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰å¾…å¤„ç†çš„å†…å®¹",
        }
    
    # æ”¶é›†æ´å¯Ÿ
    insights = []
    
    for file_path in source_files:
        try:
            content = file_manager.read_file(file_path)
            
            # è§£æå¹¶åˆ†æ
            parsed = content_parser.parse_content(content, file_path.name)
            analysis = news_analyzer.analyze(parsed)
            
            # æ ¹æ®é‡è¦æ€§è¿‡æ»¤
            if importance_filter != "all":
                if analysis.importance != importance_filter:
                    continue
            
            insights.append({
                "source": file_path.name,
                "summary": analysis.summary,
                "key_points": analysis.key_points,
                "sentiment": analysis.sentiment,
                "importance": analysis.importance,
                "industries": analysis.related_industries,
                "stocks": [s["code"] for s in analysis.related_stocks],
            })
            
        except Exception as e:
            print(f"å¤„ç† {file_path} æ—¶å‡ºé”™: {e}")
    
    if not insights:
        return {
            "insights_extracted": 0,
            "message": f"æ²¡æœ‰ç¬¦åˆæ¡ä»¶ï¼ˆé‡è¦æ€§={importance_filter}ï¼‰çš„æ´å¯Ÿ",
        }
    
    # ç”Ÿæˆç¬”è®°
    note_content = _format_insights_note(insights)
    
    # ä¿å­˜åˆ°output
    date = datetime.now().strftime(NamingConfig.DATE_FORMAT)
    filename = NamingConfig.INSIGHT_NOTE_NAME.format(date=date)
    
    note_path = file_manager.save_to_output(
        note_content, 
        filename,
        output_subfolder
    )
    
    return {
        "insights_extracted": len(insights),
        "note_path": str(note_path),
        "insights": insights,
        "message": f"å·²æå– {len(insights)} æ¡æ´å¯Ÿï¼Œä¿å­˜åˆ° {note_path}",
    }


def _format_insights_note(insights: List[dict]) -> str:
    """æ ¼å¼åŒ–æ´å¯Ÿç¬”è®°"""
    date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    lines = [
        f"# {date} æŠ•èµ„æ´å¯Ÿç¬”è®°\n",
        "## ğŸ“Š æ´å¯Ÿæ¦‚è§ˆ\n",
        f"- å…±æå– {len(insights)} æ¡é‡è¦æ´å¯Ÿ",
    ]
    
    # ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
    industry_count = {}
    for insight in insights:
        for ind in insight["industries"]:
            industry_count[ind] = industry_count.get(ind, 0) + 1
    
    if industry_count:
        top_industries = sorted(
            industry_count.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        lines.append(f"- çƒ­é—¨è¡Œä¸šï¼š{', '.join([i[0] for i in top_industries])}")
    
    lines.append("\n---\n")
    lines.append("## ğŸ” è¯¦ç»†æ´å¯Ÿ\n")
    
    for i, insight in enumerate(insights, 1):
        sentiment_emoji = {
            "positive": "ğŸ“ˆ",
            "negative": "ğŸ“‰", 
            "neutral": "â–",
        }.get(insight["sentiment"], "â–")
        
        lines.append(f"### {i}. {sentiment_emoji} {insight['summary'][:50]}...\n")
        lines.append(f"**æ¥æº**ï¼š{insight['source']}")
        lines.append(f"**é‡è¦æ€§**ï¼š{insight['importance']}")
        
        if insight["key_points"]:
            lines.append("\n**å…³é”®è¦ç‚¹**ï¼š")
            for point in insight["key_points"][:3]:
                lines.append(f"- {point}")
        
        if insight["stocks"]:
            lines.append(f"\n**ç›¸å…³è‚¡ç¥¨**ï¼š{', '.join(insight['stocks'])}")
        
        if insight["industries"]:
            lines.append(f"**ç›¸å…³è¡Œä¸š**ï¼š{', '.join(insight['industries'])}")
        
        lines.append("\n---\n")
    
    lines.append("\n## ğŸ’¡ è¡ŒåŠ¨å»ºè®®\n")
    lines.append("åŸºäºä»¥ä¸Šæ´å¯Ÿï¼Œå»ºè®®ï¼š")
    lines.append("1. æŒç»­å…³æ³¨çƒ­é—¨è¡Œä¸šçš„æ”¿ç­–åŠ¨æ€")
    lines.append("2. å¯¹å¤šæ¬¡è¢«æåŠçš„è‚¡ç¥¨åšè¿›ä¸€æ­¥ç ”ç©¶")
    lines.append("3. ç»“åˆè‡ªèº«é£é™©åå¥½åšå‡ºæŠ•èµ„å†³ç­–")
    lines.append("\n---\n")
    lines.append("*æœ¬ç¬”è®°ç”±AIè¾…åŠ©ç”Ÿæˆï¼ŒæŠ•èµ„éœ€è°¨æ…*\n")
    
    return "\n".join(lines)


def archive_processed(
    source_files: Optional[List[Path]] = None
) -> dict:
    """
    å°†å·²å¤„ç†çš„æ–‡ä»¶å½’æ¡£
    
    Args:
        source_files: è¦å½’æ¡£çš„æ–‡ä»¶åˆ—è¡¨
        
    Returns:
        å½’æ¡£ç»“æœ
    """
    if source_files is None:
        all_files = file_manager.list_all_files("processing")
        source_files = [
            Path(f["path"]) 
            for f in all_files.get("processing", [])
        ]
    
    archived = []
    for file_path in source_files:
        try:
            new_path = file_manager.move_to_archive(file_path)
            archived.append(str(new_path))
        except Exception as e:
            print(f"å½’æ¡£ {file_path} æ—¶å‡ºé”™: {e}")
    
    return {
        "archived_count": len(archived),
        "archived_files": archived,
        "message": f"å·²å½’æ¡£ {len(archived)} ä¸ªæ–‡ä»¶",
    }


if __name__ == "__main__":
    result = extract_insights()
    print(f"æ´å¯Ÿæå–å®Œæˆï¼š{result}")
